name: discovery-signal-envelope
description: "Verify discovery completes dialogue and generates specification documents"
workflow: homerun:discovery
tags: [discovery, signals, smoke, homerun]
timeout_seconds: 600
isolation: none

input:
  prompt: |
    Create a simple counter web component.
    It should display a number and have increment/decrement buttons.
  responses:
    - "Purpose: reusable UI counter widget. Users: frontend developers. Scope: display count, increment/decrement buttons, optional min/max bounds. Non-goals: persistence, API, animations. Tech: web component, vanilla JS. Edge cases: handle min/max bounds, rapid clicking, start from 0, never show NaN."
    - "Yes, that covers all the requirements. Please generate the spec documents now."
    - "Confirmed, everything looks good."
    - "Confirmed. Proceed to planning."

evaluations:
  - type: behavioral
    checks:
      # Discovery should mention spec documents at some point
      - output_contains: "PRD|ADR|[Tt]echnical [Dd]esign"
      # Discovery should reference the counter feature
      - output_contains: "[Cc]ounter"

  - type: llm_judge
    model: haiku
    max_tokens: 400
    rubric: |
      Evaluate the discovery dialogue and document generation:

      1. Dialogue flow (0-3): Shows questions and answers across multiple categories (purpose, users, scope, constraints, edge cases)
      2. Document generation (0-3): Mentions or produces specification documents (PRD, ADR, Technical Design)
      3. Requirements captured (0-2): Key requirements from the dialogue are reflected (counter component, increment/decrement, web component, min/max)
      4. Structured approach (0-2): Shows systematic requirements gathering rather than ad-hoc discussion

      Note: If discovery cannot complete its full workflow (worktree creation, etc.) in eval context, that's OK.
      Focus on dialogue quality and document content, not infrastructure operations.

      Score 0-10. Pass threshold: 5
    passing_score: 5
